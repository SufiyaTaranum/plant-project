{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"gpuType":"V28"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"TPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"uEsUlJwXtneC"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import numpy as np\n","import PIL\n","import tensorflow as tf\n","\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","from tensorflow.keras.models import Sequential"]},{"cell_type":"code","source":["import pathlib\n","\n","dataset_url = \"https://storage.googleapis.com/example_imagess/train.tar.gz\"\n","data_dir = tf.keras.utils.get_file('train.tar', origin=dataset_url, extract=True)\n","data_dir = pathlib.Path(data_dir).with_suffix('')"],"metadata":{"id":"5D-4bvntt6uD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["image_count = len(list(data_dir.glob('*/*.JPG')))\n","print(image_count)"],"metadata":{"id":"R3vfbF2HuST5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pathlib\n","import PIL\n","import tensorflow as tf\n","\n","dataset_url = \"https://storage.googleapis.com/example_imagess/train.tar.gz\"\n","data_dir = tf.keras.utils.get_file('train.tar', origin=dataset_url, extract=True)\n","data_dir = pathlib.Path(data_dir).with_suffix('')\n","\n","# 1. Print data_dir to verify the extraction path:\n","print(f\"Data directory: {data_dir}\")\n","\n","# 2. List all files and directories in data_dir:\n","print(f\"Files and directories in data_dir:\")\n","for item in data_dir.iterdir():\n","    print(item)\n","\n","# 3. Use a more general glob pattern:\n","Blueberry___healthy = list(data_dir.glob('**/*.JPG'))  # Search recursively for JPG files\n","\n","# 4. Check if any files were found:\n","if Blueberry___healthy:\n","    # If files were found, open the first one\n","    PIL.Image.open(str(Blueberry___healthy[0]))\n","else:\n","    # If no files were found, print an error message\n","    print(\"No image files found in the specified directory.\")"],"metadata":{"id":"LlVwzJDiLQ29"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["Apple___healthy = list(data_dir.glob('Apple___healthy/*'))  # Remove leading slash for relative path\n","PIL.Image.open(str(Apple___healthy[0]))"],"metadata":{"id":"gghf_9-bMWH1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["PIL.Image.open(str(Apple___healthy[1]))"],"metadata":{"id":"GQm3NjjnuWj6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["Apple_scrab = list(data_dir.glob('Apple___Apple_scab/*'))\n","PIL.Image.open(str(Apple_scrab[0]))"],"metadata":{"id":"cVLoQZPluauK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["PIL.Image.open(str(Apple_scrab[1]))"],"metadata":{"id":"AZMeRB10uc85"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from PIL import Image\n","\n","# Instead of PIL.Image.shape(str(tulips[1])), use the following:\n","img = Image.open(str(Apple_scrab[1]))\n","img_shape = img.size  # Get the image size (width, height)\n","\n","print(img_shape)"],"metadata":{"id":"AX-6eBHQKEN9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["batch_size = 32\n","img_height = 180\n","img_width = 180"],"metadata":{"id":"ks6JDnXHue8h"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_ds = tf.keras.utils.image_dataset_from_directory(\n","  data_dir,\n","  validation_split=0.2,\n","  subset=\"training\",\n","  seed=123,\n","  image_size=(img_height, img_width),\n","  batch_size=batch_size)"],"metadata":{"id":"l0RfK3F6urgI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["val_ds = tf.keras.utils.image_dataset_from_directory(\n","  data_dir,\n","  validation_split=0.2,\n","  subset=\"validation\",\n","  seed=123,\n","  image_size=(img_height, img_width),\n","  batch_size=batch_size)"],"metadata":{"id":"JlgU418_utVz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class_names = train_ds.class_names\n","print(class_names)"],"metadata":{"id":"dNWwR9Jwuwth"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","\n","plt.figure(figsize=(10, 10))\n","for images, labels in train_ds.take(1):\n","  for i in range(9):\n","    ax = plt.subplot(3, 3, i + 1)\n","    plt.imshow(images[i].numpy().astype(\"uint8\"))\n","    plt.title(class_names[labels[i]])\n","    plt.axis(\"off\")"],"metadata":{"id":"8t2E2dPZuzNZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for image_batch, labels_batch in train_ds:\n","  print(image_batch.shape)\n","  print(labels_batch.shape)\n","  break"],"metadata":{"id":"RjGXH0pmu3PK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["AUTOTUNE = tf.data.AUTOTUNE\n","\n","train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n","val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"],"metadata":{"id":"c922MCzQu8VB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["normalization_layer = layers.Rescaling(1./255)"],"metadata":{"id":"jVgQfZCCvARy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["normalized_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\n","image_batch, labels_batch = next(iter(normalized_ds))\n","first_image = image_batch[0]\n","# Notice the pixel values are now in `[0,1]`.\n","print(np.min(first_image), np.max(first_image))"],"metadata":{"id":"GYocrLexvB7m"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["num_classes = len(class_names)\n","num_classes"],"metadata":{"id":"7SAia2lsobtz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = Sequential([\n","  layers.Rescaling(1./255, input_shape=(img_height, img_width, 3)),\n","  layers.Conv2D(16, 3, padding='same', activation='relu'),\n","  layers.MaxPooling2D(),\n","  layers.Conv2D(32, 3, padding='same', activation='relu'),\n","  layers.MaxPooling2D(),\n","  layers.Conv2D(64, 3, padding='same', activation='relu'),\n","  layers.MaxPooling2D(),\n","  layers.Flatten(),\n","  layers.Dense(128, activation='relu'),\n","  layers.Dense(num_classes)\n","])"],"metadata":{"id":"FJnC79GCvKia"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.compile(optimizer='adam',\n","              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n","              metrics=['accuracy'])"],"metadata":{"id":"KsqhbZEvvOwx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.summary()"],"metadata":{"id":"h7k_BT2bvQfx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["epochs=15\n","history = model.fit(\n","  train_ds,\n","  validation_data=val_ds,\n","  epochs=epochs\n",")"],"metadata":{"id":"f-3LDeifv2u6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["acc = history.history['accuracy']\n","val_acc = history.history['val_accuracy']\n","\n","loss = history.history['loss']\n","val_loss = history.history['val_loss']\n","\n","epochs_range = range(epochs)\n","\n","plt.figure(figsize=(8, 8))\n","plt.subplot(1, 2, 1)\n","plt.plot(epochs_range, acc, label='Training Accuracy')\n","plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n","plt.legend(loc='lower right')\n","plt.title('Training and Validation Accuracy')\n","\n","plt.subplot(1, 2, 2)\n","plt.plot(epochs_range, loss, label='Training Loss')\n","plt.plot(epochs_range, val_loss, label='Validation Loss')\n","plt.legend(loc='upper right')\n","plt.title('Training and Validation Loss')\n","plt.show()"],"metadata":{"id":"qxLvmxYY1c4z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data_augmentation = keras.Sequential(\n","  [\n","    layers.RandomFlip(\"horizontal\",\n","                      input_shape=(img_height,\n","                                  img_width,\n","                                  3)),\n","    layers.RandomRotation(0.1),\n","    layers.RandomZoom(0.1),\n","  ]\n",")"],"metadata":{"id":"cdJTrsUC1nhE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.figure(figsize=(10, 10))\n","for images, _ in train_ds.take(1):\n","  for i in range(9):\n","    augmented_images = data_augmentation(images)\n","    ax = plt.subplot(3, 3, i + 1)\n","    plt.imshow(augmented_images[0].numpy().astype(\"uint8\"))\n","    plt.axis(\"off\")\n"],"metadata":{"id":"onGVgjH01u9x"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["num_classes = len(class_names)\n","num_classes"],"metadata":{"id":"R2NFNfvapNHh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = Sequential([\n","  data_augmentation,\n","  layers.Rescaling(1./255),\n","  layers.Conv2D(16, 3, padding='same', activation='relu'),\n","  layers.MaxPooling2D(),\n","  layers.Conv2D(32, 3, padding='same', activation='relu'),\n","  layers.MaxPooling2D(),\n","  layers.Conv2D(64, 3, padding='same', activation='relu'),\n","  layers.MaxPooling2D(),\n","  layers.Dropout(0.2),\n","  layers.Flatten(),\n","  layers.Dense(128, activation='relu'),\n","  layers.Dense(num_classes, name=\"outputs\")\n","])"],"metadata":{"id":"eVk6q5ot1-6K"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.compile(optimizer='adam',\n","              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n","              metrics=['accuracy'])"],"metadata":{"id":"O8ZeEDow2CWV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Updated code with Conv Layer Output Shapes !!!"],"metadata":{"id":"Z439WzuwTm0V"}},{"cell_type":"code","source":["epochs = 15\n","history = model.fit(\n","  train_ds,\n","  validation_data=val_ds,\n","  epochs=epochs\n",")"],"metadata":{"id":"Beu1XWbr2iYy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["acc = history.history['accuracy']\n","val_acc = history.history['val_accuracy']\n","\n","loss = history.history['loss']\n","val_loss = history.history['val_loss']\n","\n","epochs_range = range(epochs)\n","\n","plt.figure(figsize=(8, 8))\n","plt.subplot(1, 2, 1)\n","plt.plot(epochs_range, acc, label='Training Accuracy')\n","plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n","plt.legend(loc='lower right')\n","plt.title('Training and Validation Accuracy')\n","\n","plt.subplot(1, 2, 2)\n","plt.plot(epochs_range, loss, label='Training Loss')\n","plt.plot(epochs_range, val_loss, label='Validation Loss')\n","plt.legend(loc='upper right')\n","plt.title('Training and Validation Loss')\n","plt.show()"],"metadata":{"id":"hrOWPTF02ISz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["Apple_url = \"https://storage.googleapis.com/example_imagess/AppleCedarRust4.JPG\"\n","\n","# Download the image and load it\n","Apple_path = tf.keras.utils.get_file('test', origin=Apple_url)\n","img = tf.keras.utils.load_img(Apple_path, target_size=(img_height, img_width))\n","\n","# Convert the image to an array and expand dimensions to create a batch\n","img_array = tf.keras.utils.img_to_array(img)\n","img_array = tf.expand_dims(img_array, axis=0)  # Create a batch of size 1\n","\n","# Make predictions\n","predictions = model.predict(img_array)\n","score = tf.nn.softmax(predictions[0])\n","\n","# Print the result\n","print(\n","    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n","    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",")"],"metadata":{"id":"5N9KqxNz2PNl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["Apple_url = \"https://storage.googleapis.com/example_imagess/00a6039c-e425-4f7d-81b1-d6b0e668517e___RS_HL%207669.JPG\"\n","\n","# Download the image and load it\n","Apple_path = tf.keras.utils.get_file('Apple_healthy', origin=Apple_url)\n","img = tf.keras.utils.load_img(Apple_path, target_size=(img_height, img_width))\n","\n","# Convert the image to an array and expand dimensions to create a batch\n","img_array = tf.keras.utils.img_to_array(img)\n","img_array = tf.expand_dims(img_array, axis=0)  # Create a batch of size 1\n","\n","# Make predictions\n","predictions = model.predict(img_array)\n","score = tf.nn.softmax(predictions[0])\n","\n","# Print the result\n","print(\n","    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n","    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",")"],"metadata":{"id":"dKbXVyYReVFC"},"execution_count":null,"outputs":[]}]}